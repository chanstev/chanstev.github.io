---
title: "Start governing AI by including ethical principles in existing EA framework"
date: 2019-06-17
categories:
  - Tech
tags:
  - ai-ethics
  - enterprise-architecture
  - governance
  - best-practices
  - responsible-ai
---
![Start governing AI by including ethical principles in existing EA framework](/assets/images/posts/2019-06-17-start-ai-governing.png)
([Chinese version is published in Oriental Daily on the same day](https://orientaldaily.on.cc/cnt/finance/20190617/00275_001.html))

With the rapid development of cloud platforms and machine learning, Artificial Intelligence (AI) is being applied to many aspects of our daily life.

You can use your voice to search for driving directions, unlock your phone and computer with facial recognition, digital assistants can help to arrange your schedule, and some businesses started to serve customers via chatbot. Today's computers already can see, can speak, can listen and even comparable to humans under certain circumstances. Now we can enjoy the convenience and operational efficiency by using AI at a relatively low cost, sometimes even free. However, we should also aware the scalability of AI technologies, its wide adoption can create a significant impact on society.

I am not worried about SciFi-like ["Strong AI"](https://en.wikipedia.org/wiki/Strong_AI) having its consciousness as it is too far from reality. The current AI is still like a toddler trying to mimic whatever human do and able to multiply it massively, be either the right or wrong side. They don't have a built-in conscience to stop them in doing evil yet. Therefore, we should not only ask what AI can do now but also concern what AI should do.

Society and enterprises should establish management structures to ensure that the development and application of AI can comply with both legal and ethical requirements, preventing the use of AI technology in wrong areas. Enterprise architects should add AI development and application principles into the existing EA framework and trigger the proper governance in place. Referring to some published AI principles in the industry could be an excellent place to start with.

Here are some examples of principles that have been made public:

Fairness - AI systems should treat all people fairly, avoid creating or reinforcing unfair prejudices;
Inclusiveness - AI systems should empower everyone and engage people, so that the technology can be accessible and benefit to all humans;
Transparency - AI systems should be understandable, allowing humans to understand how these technologies view and analyze the world;
Privacy & Security - AI systems should be secure and respect privacy, taking measures to protect the confidentiality of people and organizations;
Accountability - AI should have an algorithmic accountability system that people can remove unintentional harm.
Although the sample principles above seem obvious like common sense, different cultures may have different priorities and interpretations. The Massachusetts Institute of Technology designed an online experiment called the [Ethics Machine](http://moralmachine.mit.edu/) in 2014, assuming that an autonomous car has to make moral dilemma of life-or-death choices, collecting millions of people from 233 countries and regions, 40 million decisions. [The study](https://www.technologyreview.com/s/612341/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/) suggested that people's moral preferences vary according to cultural and economic differences.

These different moral preferences are affecting the development of our application of AI. Take security surveillance as an example: [some cities are massively deploying smart camera](https://www.bbc.com/news/av/world-asia-china-42248056/in-your-face-china-s-all-seeing-state) with facial recognition technology to help manage cities, ranging from counter-terrorism to [reducing jaywalkers](https://www.scmp.com/tech/china-tech/article/2138960/jaywalkers-under-surveillance-shenzhen-soon-be-punished-text). On the other hand, [San Francisco](https://www.bbc.com/news/technology-48276660) just passed a ban on the procurement and use of face recognition technology by local police and other parts of the city government to protect public privacy and civil rights. It can be seen that the AI adoption principles in different societies can be quite different.

To ensure technology adoptions align with organization's core value is one of the missions of enterprise architecture practices. Architects should start leveraging industry published principles as a blueprint, and actively lead the organization to discuss and develop a set of AI application principles and guidelines which is more in line with the institutional environment. If we have more institutions to make their AI principles public, the society can *have a stronger foundation to discuss the relevant legislative regulations*, which I believe will be conducive to the healthy development of AI in the long run. 